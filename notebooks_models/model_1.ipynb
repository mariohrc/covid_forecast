{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "cwd = os.getcwd()\n",
    "os.chdir('../')\n",
    "os.getcwd()\n",
    "from py_scripts.test_models_plot_roc_auc_curve import test_models_plot_roc_auc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modif_1 = pd.read_csv('./data/manipulated_covid_data.csv') #Importa os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  0\n",
       "sex                         0\n",
       "patient_type                0\n",
       "intubed                     0\n",
       "pneumonia                   0\n",
       "age                         0\n",
       "pregnancy                   0\n",
       "diabetes                    0\n",
       "copd                        0\n",
       "asthma                      0\n",
       "inmsupr                     0\n",
       "hypertension                0\n",
       "other_disease               0\n",
       "cardiovascular              0\n",
       "obesity                     0\n",
       "renal_chronic               0\n",
       "tobacco                     0\n",
       "contact_other_covid    152277\n",
       "covid_res                   0\n",
       "icu                         0\n",
       "age_cat                  1992\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modif_1.isnull().sum() #Verifica os nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_modif_1.drop(['covid_res', 'Unnamed: 0','age_cat','contact_other_covid'], axis = 1) #Remove colunas não utilizadas e com muitos NANs não trataveis\n",
    "y = df_modif_1['covid_res'] #Cria coluna alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42,\n",
    "                                                    stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42) #Faz undersample devido a perda de poucos dados relacionados ao total\n",
    "X_res2, y_res2 = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42) #Faz um SMOTE para comparação com Under\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "list_models = [\n",
    "{'model_name': 'Decision Tree',\n",
    " 'estimator' : DecisionTreeClassifier(random_state = random_seed)},\n",
    "{'model_name': 'Random Forest',\n",
    " 'estimator' : RandomForestClassifier(random_state = random_seed)}, \n",
    "{'model_name': 'AdaBoost',\n",
    " 'estimator' : AdaBoostClassifier(random_state = random_seed)},\n",
    "{'model_name': 'GradientBoosting',\n",
    " 'estimator' : GradientBoostingClassifier(random_state = random_seed)},\n",
    "{'model_name': 'XGBoost',\n",
    " 'estimator' : XGBClassifier(random_state = random_seed)},\n",
    "{'model_name': 'LightGBM',\n",
    " 'estimator' : lgb.LGBMClassifier(random_state = random_seed)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-2e0f24f75472>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                               \u001b[1;34m\"model_name\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[1;34m\"estimator\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                               \u001b[0mX_res\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m                               \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                               \u001b[0my_res\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_res' is not defined"
     ]
    }
   ],
   "source": [
    "test_models_plot_roc_auc_curve(list_models, #Plota curva com SMOTE\n",
    "                              \"model_name\",\n",
    "                              \"estimator\",\n",
    "                              X_res,\n",
    "                              X_test,\n",
    "                              y_res,\n",
    "                              y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grad = GradientBoostingClassifier(random_state = 42, \n",
    "                                      n_estimators=500, verbose=2,\n",
    "                                      max_depth=5, loss='exponential', \n",
    "                                      learning_rate=0.1)\n",
    "\n",
    "clf_xgb = XGBClassifier(max_depth=7, \n",
    "                        eta=1, \n",
    "                        silent=1,\n",
    "                        objective= 'binary:logistic',\n",
    "                        eval_metric='auc',\n",
    "                        learning_rate=0.05)\n",
    "\n",
    "clf_lgb = lgb.LGBMClassifier(random_state = 42,\n",
    "                             n_estimators=500, verbose=2,\n",
    "                             max_depth=5, loss='exponential',\n",
    "                             learning_rate=0.3,\n",
    "                             boosting_type='dart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.9930            3.85m\n",
      "         2           0.9872            3.87m\n",
      "         3           0.9823            3.87m\n",
      "         4           0.9783            3.88m\n",
      "         5           0.9748            3.87m\n",
      "         6           0.9719            3.91m\n",
      "         7           0.9695            3.98m\n",
      "         8           0.9675            4.01m\n",
      "         9           0.9657            3.99m\n",
      "        10           0.9642            4.00m\n",
      "        11           0.9629            4.01m\n",
      "        12           0.9619            4.02m\n",
      "        13           0.9609            4.00m\n",
      "        14           0.9601            4.00m\n",
      "        15           0.9594            4.01m\n",
      "        16           0.9587            3.99m\n",
      "        17           0.9581            4.00m\n",
      "        18           0.9576            3.98m\n",
      "        19           0.9572            3.96m\n",
      "        20           0.9568            3.94m\n",
      "        21           0.9564            3.93m\n",
      "        22           0.9561            3.92m\n",
      "        23           0.9558            3.92m\n",
      "        24           0.9555            3.90m\n",
      "        25           0.9552            3.90m\n",
      "        26           0.9549            3.88m\n",
      "        27           0.9547            3.88m\n",
      "        28           0.9544            3.88m\n",
      "        29           0.9542            3.87m\n",
      "        30           0.9539            3.86m\n",
      "        31           0.9537            3.84m\n",
      "        32           0.9535            3.83m\n",
      "        33           0.9533            3.82m\n",
      "        34           0.9531            3.81m\n",
      "        35           0.9529            3.78m\n",
      "        36           0.9528            3.77m\n",
      "        37           0.9526            3.76m\n",
      "        38           0.9524            3.74m\n",
      "        39           0.9523            3.74m\n",
      "        40           0.9521            3.72m\n",
      "        41           0.9519            3.71m\n",
      "        42           0.9518            3.71m\n",
      "        43           0.9517            3.69m\n",
      "        44           0.9515            3.67m\n",
      "        45           0.9514            3.66m\n",
      "        46           0.9513            3.65m\n",
      "        47           0.9512            3.63m\n",
      "        48           0.9510            3.61m\n",
      "        49           0.9509            3.61m\n",
      "        50           0.9508            3.59m\n",
      "        51           0.9507            3.58m\n",
      "        52           0.9506            3.57m\n",
      "        53           0.9505            3.56m\n",
      "        54           0.9504            3.54m\n",
      "        55           0.9503            3.53m\n",
      "        56           0.9502            3.52m\n",
      "        57           0.9501            3.51m\n",
      "        58           0.9500            3.50m\n",
      "        59           0.9499            3.49m\n",
      "        60           0.9498            3.47m\n",
      "        61           0.9497            3.46m\n",
      "        62           0.9496            3.45m\n",
      "        63           0.9496            3.43m\n",
      "        64           0.9495            3.42m\n",
      "        65           0.9494            3.42m\n",
      "        66           0.9493            3.40m\n",
      "        67           0.9492            3.39m\n",
      "        68           0.9491            3.38m\n",
      "        69           0.9490            3.37m\n",
      "        70           0.9490            3.36m\n",
      "        71           0.9489            3.35m\n",
      "        72           0.9488            3.34m\n",
      "        73           0.9488            3.33m\n",
      "        74           0.9487            3.32m\n",
      "        75           0.9486            3.31m\n",
      "        76           0.9486            3.30m\n",
      "        77           0.9485            3.29m\n",
      "        78           0.9484            3.29m\n",
      "        79           0.9484            3.28m\n",
      "        80           0.9483            3.27m\n",
      "        81           0.9482            3.26m\n",
      "        82           0.9482            3.24m\n",
      "        83           0.9481            3.24m\n",
      "        84           0.9481            3.23m\n",
      "        85           0.9480            3.22m\n",
      "        86           0.9480            3.21m\n",
      "        87           0.9479            3.19m\n",
      "        88           0.9479            3.18m\n",
      "        89           0.9478            3.18m\n",
      "        90           0.9477            3.17m\n",
      "        91           0.9477            3.16m\n",
      "        92           0.9477            3.15m\n",
      "        93           0.9476            3.14m\n",
      "        94           0.9476            3.13m\n",
      "        95           0.9475            3.12m\n",
      "        96           0.9475            3.11m\n",
      "        97           0.9474            3.10m\n",
      "        98           0.9474            3.10m\n",
      "        99           0.9474            3.08m\n",
      "       100           0.9473            3.08m\n",
      "       101           0.9473            3.07m\n",
      "       102           0.9472            3.06m\n",
      "       103           0.9472            3.05m\n",
      "       104           0.9471            3.04m\n",
      "       105           0.9471            3.03m\n",
      "       106           0.9470            3.03m\n",
      "       107           0.9470            3.02m\n",
      "       108           0.9470            3.01m\n",
      "       109           0.9469            3.00m\n",
      "       110           0.9469            2.99m\n",
      "       111           0.9469            2.98m\n",
      "       112           0.9468            2.98m\n",
      "       113           0.9468            2.97m\n",
      "       114           0.9467            2.97m\n",
      "       115           0.9467            2.96m\n",
      "       116           0.9467            2.95m\n",
      "       117           0.9466            2.94m\n",
      "       118           0.9466            2.93m\n",
      "       119           0.9466            2.92m\n",
      "       120           0.9465            2.92m\n",
      "       121           0.9465            2.91m\n",
      "       122           0.9465            2.90m\n",
      "       123           0.9465            2.89m\n",
      "       124           0.9464            2.88m\n",
      "       125           0.9464            2.87m\n",
      "       126           0.9463            2.86m\n",
      "       127           0.9463            2.86m\n",
      "       128           0.9463            2.85m\n",
      "       129           0.9463            2.84m\n",
      "       130           0.9462            2.84m\n",
      "       131           0.9462            2.83m\n",
      "       132           0.9461            2.82m\n",
      "       133           0.9461            2.82m\n",
      "       134           0.9461            2.81m\n",
      "       135           0.9460            2.80m\n",
      "       136           0.9460            2.80m\n",
      "       137           0.9460            2.79m\n",
      "       138           0.9459            2.78m\n",
      "       139           0.9459            2.77m\n",
      "       140           0.9459            2.76m\n",
      "       141           0.9459            2.75m\n",
      "       142           0.9459            2.75m\n",
      "       143           0.9458            2.74m\n",
      "       144           0.9458            2.73m\n",
      "       145           0.9458            2.72m\n",
      "       146           0.9457            2.71m\n",
      "       147           0.9457            2.70m\n",
      "       148           0.9457            2.70m\n",
      "       149           0.9456            2.69m\n",
      "       150           0.9456            2.68m\n",
      "       151           0.9456            2.68m\n",
      "       152           0.9455            2.67m\n",
      "       153           0.9455            2.66m\n",
      "       154           0.9455            2.65m\n",
      "       155           0.9455            2.64m\n",
      "       156           0.9454            2.63m\n",
      "       157           0.9454            2.63m\n",
      "       158           0.9454            2.62m\n",
      "       159           0.9454            2.61m\n",
      "       160           0.9454            2.60m\n",
      "       161           0.9453            2.60m\n",
      "       162           0.9453            2.59m\n",
      "       163           0.9453            2.58m\n",
      "       164           0.9453            2.57m\n",
      "       165           0.9452            2.56m\n",
      "       166           0.9452            2.56m\n",
      "       167           0.9452            2.55m\n",
      "       168           0.9452            2.54m\n",
      "       169           0.9452            2.53m\n",
      "       170           0.9451            2.52m\n",
      "       171           0.9451            2.52m\n",
      "       172           0.9451            2.51m\n",
      "       173           0.9451            2.50m\n",
      "       174           0.9450            2.49m\n",
      "       175           0.9450            2.48m\n",
      "       176           0.9450            2.48m\n",
      "       177           0.9450            2.47m\n",
      "       178           0.9450            2.46m\n",
      "       179           0.9449            2.45m\n",
      "       180           0.9449            2.45m\n",
      "       181           0.9449            2.44m\n",
      "       182           0.9449            2.43m\n",
      "       183           0.9449            2.43m\n",
      "       184           0.9448            2.42m\n",
      "       185           0.9448            2.41m\n",
      "       186           0.9448            2.40m\n",
      "       187           0.9448            2.40m\n",
      "       188           0.9448            2.39m\n",
      "       189           0.9447            2.38m\n",
      "       190           0.9447            2.37m\n",
      "       191           0.9447            2.36m\n",
      "       192           0.9447            2.36m\n",
      "       193           0.9447            2.35m\n",
      "       194           0.9447            2.34m\n",
      "       195           0.9446            2.33m\n",
      "       196           0.9446            2.32m\n",
      "       197           0.9446            2.32m\n",
      "       198           0.9446            2.31m\n",
      "       199           0.9446            2.30m\n",
      "       200           0.9446            2.29m\n",
      "       201           0.9445            2.28m\n",
      "       202           0.9445            2.28m\n",
      "       203           0.9445            2.27m\n",
      "       204           0.9445            2.26m\n",
      "       205           0.9445            2.25m\n",
      "       206           0.9444            2.24m\n",
      "       207           0.9444            2.24m\n",
      "       208           0.9444            2.23m\n",
      "       209           0.9444            2.22m\n",
      "       210           0.9444            2.21m\n",
      "       211           0.9444            2.21m\n",
      "       212           0.9444            2.20m\n",
      "       213           0.9444            2.19m\n",
      "       214           0.9444            2.18m\n",
      "       215           0.9443            2.17m\n",
      "       216           0.9443            2.16m\n",
      "       217           0.9443            2.16m\n",
      "       218           0.9443            2.15m\n",
      "       219           0.9443            2.14m\n",
      "       220           0.9443            2.14m\n",
      "       221           0.9442            2.13m\n",
      "       222           0.9442            2.12m\n",
      "       223           0.9442            2.11m\n",
      "       224           0.9442            2.10m\n",
      "       225           0.9442            2.10m\n",
      "       226           0.9442            2.09m\n",
      "       227           0.9441            2.08m\n",
      "       228           0.9441            2.07m\n",
      "       229           0.9441            2.07m\n",
      "       230           0.9441            2.06m\n",
      "       231           0.9441            2.05m\n",
      "       232           0.9441            2.04m\n",
      "       233           0.9440            2.03m\n",
      "       234           0.9440            2.03m\n",
      "       235           0.9440            2.02m\n",
      "       236           0.9440            2.01m\n",
      "       237           0.9440            2.00m\n",
      "       238           0.9440            2.00m\n",
      "       239           0.9440            1.99m\n",
      "       240           0.9439            1.98m\n",
      "       241           0.9439            1.97m\n",
      "       242           0.9439            1.97m\n",
      "       243           0.9439            1.96m\n",
      "       244           0.9439            1.95m\n",
      "       245           0.9439            1.94m\n",
      "       246           0.9438            1.94m\n",
      "       247           0.9438            1.93m\n",
      "       248           0.9438            1.92m\n",
      "       249           0.9438            1.91m\n",
      "       250           0.9438            1.90m\n",
      "       251           0.9438            1.90m\n",
      "       252           0.9438            1.89m\n",
      "       253           0.9437            1.88m\n",
      "       254           0.9437            1.87m\n",
      "       255           0.9437            1.87m\n",
      "       256           0.9437            1.86m\n",
      "       257           0.9437            1.85m\n",
      "       258           0.9437            1.84m\n",
      "       259           0.9437            1.83m\n",
      "       260           0.9437            1.83m\n",
      "       261           0.9437            1.82m\n",
      "       262           0.9437            1.81m\n",
      "       263           0.9436            1.80m\n",
      "       264           0.9436            1.80m\n",
      "       265           0.9436            1.79m\n",
      "       266           0.9436            1.78m\n",
      "       267           0.9436            1.77m\n",
      "       268           0.9436            1.76m\n",
      "       269           0.9436            1.76m\n",
      "       270           0.9435            1.75m\n",
      "       271           0.9435            1.74m\n",
      "       272           0.9435            1.73m\n",
      "       273           0.9435            1.73m\n",
      "       274           0.9435            1.72m\n",
      "       275           0.9435            1.71m\n",
      "       276           0.9434            1.70m\n",
      "       277           0.9434            1.70m\n",
      "       278           0.9434            1.69m\n",
      "       279           0.9434            1.68m\n",
      "       280           0.9434            1.67m\n",
      "       281           0.9434            1.67m\n",
      "       282           0.9434            1.66m\n",
      "       283           0.9433            1.65m\n",
      "       284           0.9433            1.64m\n",
      "       285           0.9433            1.64m\n",
      "       286           0.9433            1.63m\n",
      "       287           0.9433            1.62m\n",
      "       288           0.9433            1.61m\n",
      "       289           0.9433            1.60m\n",
      "       290           0.9433            1.60m\n",
      "       291           0.9432            1.59m\n",
      "       292           0.9432            1.58m\n",
      "       293           0.9432            1.57m\n",
      "       294           0.9432            1.56m\n",
      "       295           0.9432            1.56m\n",
      "       296           0.9432            1.55m\n",
      "       297           0.9432            1.54m\n",
      "       298           0.9432            1.53m\n",
      "       299           0.9432            1.53m\n",
      "       300           0.9431            1.52m\n",
      "       301           0.9431            1.51m\n",
      "       302           0.9431            1.50m\n",
      "       303           0.9431            1.49m\n",
      "       304           0.9431            1.49m\n",
      "       305           0.9431            1.48m\n",
      "       306           0.9431            1.47m\n",
      "       307           0.9431            1.46m\n",
      "       308           0.9430            1.46m\n",
      "       309           0.9430            1.45m\n",
      "       310           0.9430            1.44m\n",
      "       311           0.9430            1.43m\n",
      "       312           0.9430            1.43m\n",
      "       313           0.9430            1.42m\n",
      "       314           0.9430            1.41m\n",
      "       315           0.9430            1.40m\n",
      "       316           0.9430            1.40m\n",
      "       317           0.9429            1.39m\n",
      "       318           0.9429            1.38m\n",
      "       319           0.9429            1.37m\n",
      "       320           0.9429            1.37m\n",
      "       321           0.9429            1.36m\n",
      "       322           0.9429            1.35m\n",
      "       323           0.9429            1.34m\n",
      "       324           0.9429            1.34m\n",
      "       325           0.9428            1.33m\n",
      "       326           0.9428            1.32m\n",
      "       327           0.9428            1.31m\n",
      "       328           0.9428            1.31m\n",
      "       329           0.9428            1.30m\n",
      "       330           0.9428            1.29m\n",
      "       331           0.9428            1.28m\n",
      "       332           0.9427            1.28m\n",
      "       333           0.9427            1.27m\n",
      "       334           0.9427            1.26m\n",
      "       335           0.9427            1.25m\n",
      "       336           0.9427            1.25m\n",
      "       337           0.9427            1.24m\n",
      "       338           0.9427            1.23m\n",
      "       339           0.9427            1.22m\n",
      "       340           0.9426            1.22m\n",
      "       341           0.9426            1.21m\n",
      "       342           0.9426            1.20m\n",
      "       343           0.9426            1.19m\n",
      "       344           0.9426            1.19m\n",
      "       345           0.9426            1.18m\n",
      "       346           0.9426            1.17m\n",
      "       347           0.9426            1.16m\n",
      "       348           0.9426            1.15m\n",
      "       349           0.9426            1.15m\n",
      "       350           0.9425            1.14m\n",
      "       351           0.9425            1.13m\n",
      "       352           0.9425            1.13m\n",
      "       353           0.9425            1.12m\n",
      "       354           0.9425            1.11m\n",
      "       355           0.9425            1.10m\n",
      "       356           0.9425            1.10m\n",
      "       357           0.9425            1.09m\n",
      "       358           0.9425            1.08m\n",
      "       359           0.9424            1.07m\n",
      "       360           0.9424            1.07m\n",
      "       361           0.9424            1.06m\n",
      "       362           0.9424            1.05m\n",
      "       363           0.9424            1.04m\n",
      "       364           0.9424            1.03m\n",
      "       365           0.9424            1.03m\n",
      "       366           0.9424            1.02m\n",
      "       367           0.9424            1.01m\n",
      "       368           0.9424            1.00m\n",
      "       369           0.9423           59.82s\n",
      "       370           0.9423           59.36s\n",
      "       371           0.9423           58.91s\n",
      "       372           0.9423           58.45s\n",
      "       373           0.9423           58.01s\n",
      "       374           0.9423           57.55s\n",
      "       375           0.9423           57.10s\n",
      "       376           0.9423           56.65s\n",
      "       377           0.9423           56.21s\n",
      "       378           0.9423           55.77s\n",
      "       379           0.9422           55.31s\n",
      "       380           0.9422           54.87s\n",
      "       381           0.9422           54.43s\n",
      "       382           0.9422           53.97s\n",
      "       383           0.9422           53.51s\n",
      "       384           0.9422           53.06s\n",
      "       385           0.9422           52.60s\n",
      "       386           0.9422           52.14s\n",
      "       387           0.9422           51.69s\n",
      "       388           0.9422           51.22s\n",
      "       389           0.9421           50.77s\n",
      "       390           0.9421           50.32s\n",
      "       391           0.9421           49.86s\n",
      "       392           0.9421           49.41s\n",
      "       393           0.9421           48.95s\n",
      "       394           0.9421           48.49s\n",
      "       395           0.9421           48.02s\n",
      "       396           0.9421           47.57s\n",
      "       397           0.9421           47.12s\n",
      "       398           0.9421           46.65s\n",
      "       399           0.9421           46.19s\n",
      "       400           0.9421           45.73s\n",
      "       401           0.9420           45.27s\n",
      "       402           0.9420           44.82s\n",
      "       403           0.9420           44.36s\n",
      "       404           0.9420           43.91s\n",
      "       405           0.9420           43.44s\n",
      "       406           0.9420           42.97s\n",
      "       407           0.9420           42.50s\n",
      "       408           0.9420           42.05s\n",
      "       409           0.9420           41.58s\n",
      "       410           0.9420           41.12s\n",
      "       411           0.9419           40.66s\n",
      "       412           0.9419           40.20s\n",
      "       413           0.9419           39.74s\n",
      "       414           0.9419           39.28s\n",
      "       415           0.9419           38.82s\n",
      "       416           0.9419           38.35s\n",
      "       417           0.9419           37.89s\n",
      "       418           0.9419           37.43s\n",
      "       419           0.9419           36.97s\n",
      "       420           0.9419           36.51s\n",
      "       421           0.9418           36.05s\n",
      "       422           0.9418           35.60s\n",
      "       423           0.9418           35.14s\n",
      "       424           0.9418           34.69s\n",
      "       425           0.9418           34.23s\n",
      "       426           0.9418           33.78s\n",
      "       427           0.9418           33.32s\n",
      "       428           0.9418           32.87s\n",
      "       429           0.9418           32.41s\n",
      "       430           0.9418           31.95s\n",
      "       431           0.9418           31.49s\n",
      "       432           0.9417           31.03s\n",
      "       433           0.9417           30.58s\n",
      "       434           0.9417           30.11s\n",
      "       435           0.9417           29.66s\n",
      "       436           0.9417           29.20s\n",
      "       437           0.9417           28.75s\n",
      "       438           0.9417           28.29s\n",
      "       439           0.9417           27.84s\n",
      "       440           0.9417           27.39s\n",
      "       441           0.9417           26.93s\n",
      "       442           0.9417           26.48s\n",
      "       443           0.9417           26.03s\n",
      "       444           0.9416           25.58s\n",
      "       445           0.9416           25.13s\n",
      "       446           0.9416           24.67s\n",
      "       447           0.9416           24.22s\n",
      "       448           0.9416           23.76s\n",
      "       449           0.9416           23.30s\n",
      "       450           0.9416           22.84s\n",
      "       451           0.9416           22.38s\n",
      "       452           0.9416           21.92s\n",
      "       453           0.9416           21.46s\n",
      "       454           0.9416           21.00s\n",
      "       455           0.9416           20.55s\n",
      "       456           0.9415           20.10s\n",
      "       457           0.9415           19.65s\n",
      "       458           0.9415           19.20s\n",
      "       459           0.9415           18.74s\n",
      "       460           0.9415           18.29s\n",
      "       461           0.9415           17.84s\n",
      "       462           0.9415           17.38s\n",
      "       463           0.9415           16.92s\n",
      "       464           0.9415           16.46s\n",
      "       465           0.9415           16.01s\n",
      "       466           0.9415           15.56s\n",
      "       467           0.9414           15.11s\n",
      "       468           0.9414           14.66s\n",
      "       469           0.9414           14.20s\n",
      "       470           0.9414           13.74s\n",
      "       471           0.9414           13.28s\n",
      "       472           0.9414           12.83s\n",
      "       473           0.9414           12.37s\n",
      "       474           0.9414           11.91s\n",
      "       475           0.9414           11.45s\n",
      "       476           0.9414           11.00s\n",
      "       477           0.9414           10.54s\n",
      "       478           0.9414           10.09s\n",
      "       479           0.9414            9.63s\n",
      "       480           0.9413            9.18s\n",
      "       481           0.9413            8.72s\n",
      "       482           0.9413            8.26s\n",
      "       483           0.9413            7.80s\n",
      "       484           0.9413            7.34s\n",
      "       485           0.9413            6.88s\n",
      "       486           0.9413            6.43s\n",
      "       487           0.9413            5.97s\n",
      "       488           0.9413            5.51s\n",
      "       489           0.9413            5.05s\n",
      "       490           0.9413            4.59s\n",
      "       491           0.9413            4.13s\n",
      "       492           0.9413            3.67s\n",
      "       493           0.9412            3.21s\n",
      "       494           0.9412            2.76s\n",
      "       495           0.9412            2.30s\n",
      "       496           0.9412            1.84s\n",
      "       497           0.9412            1.38s\n",
      "       498           0.9412            0.92s\n",
      "       499           0.9412            0.46s\n",
      "       500           0.9412            0.00s\n",
      "[16:38:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.64825\tvalidation_0-error:0.39039\tvalidation_1-auc:0.64566\tvalidation_1-error:0.36934\n",
      "[1]\tvalidation_0-auc:0.64842\tvalidation_0-error:0.39030\tvalidation_1-auc:0.64576\tvalidation_1-error:0.36931\n",
      "[2]\tvalidation_0-auc:0.64883\tvalidation_0-error:0.39009\tvalidation_1-auc:0.64609\tvalidation_1-error:0.36909\n",
      "[3]\tvalidation_0-auc:0.64923\tvalidation_0-error:0.39001\tvalidation_1-auc:0.64653\tvalidation_1-error:0.36903\n",
      "[4]\tvalidation_0-auc:0.64969\tvalidation_0-error:0.38988\tvalidation_1-auc:0.64723\tvalidation_1-error:0.36904\n",
      "[5]\tvalidation_0-auc:0.65003\tvalidation_0-error:0.38981\tvalidation_1-auc:0.64738\tvalidation_1-error:0.36895\n",
      "[6]\tvalidation_0-auc:0.65062\tvalidation_0-error:0.38965\tvalidation_1-auc:0.64801\tvalidation_1-error:0.36893\n",
      "[7]\tvalidation_0-auc:0.65083\tvalidation_0-error:0.38961\tvalidation_1-auc:0.64813\tvalidation_1-error:0.36905\n",
      "[8]\tvalidation_0-auc:0.65142\tvalidation_0-error:0.38947\tvalidation_1-auc:0.64859\tvalidation_1-error:0.36888\n",
      "[9]\tvalidation_0-auc:0.65182\tvalidation_0-error:0.38968\tvalidation_1-auc:0.64880\tvalidation_1-error:0.36851\n",
      "[10]\tvalidation_0-auc:0.65206\tvalidation_0-error:0.38968\tvalidation_1-auc:0.64894\tvalidation_1-error:0.36825\n",
      "[11]\tvalidation_0-auc:0.65218\tvalidation_0-error:0.38963\tvalidation_1-auc:0.64898\tvalidation_1-error:0.36831\n",
      "[12]\tvalidation_0-auc:0.65241\tvalidation_0-error:0.38947\tvalidation_1-auc:0.64912\tvalidation_1-error:0.36863\n",
      "[13]\tvalidation_0-auc:0.65271\tvalidation_0-error:0.38931\tvalidation_1-auc:0.64936\tvalidation_1-error:0.36871\n",
      "[14]\tvalidation_0-auc:0.65281\tvalidation_0-error:0.38943\tvalidation_1-auc:0.64935\tvalidation_1-error:0.36885\n",
      "[15]\tvalidation_0-auc:0.65299\tvalidation_0-error:0.38907\tvalidation_1-auc:0.64947\tvalidation_1-error:0.36882\n",
      "[16]\tvalidation_0-auc:0.65318\tvalidation_0-error:0.38881\tvalidation_1-auc:0.64955\tvalidation_1-error:0.36872\n",
      "[17]\tvalidation_0-auc:0.65333\tvalidation_0-error:0.38873\tvalidation_1-auc:0.64964\tvalidation_1-error:0.36886\n",
      "[18]\tvalidation_0-auc:0.65350\tvalidation_0-error:0.38861\tvalidation_1-auc:0.64970\tvalidation_1-error:0.36889\n",
      "[19]\tvalidation_0-auc:0.65363\tvalidation_0-error:0.38855\tvalidation_1-auc:0.64965\tvalidation_1-error:0.36900\n",
      "[20]\tvalidation_0-auc:0.65384\tvalidation_0-error:0.38848\tvalidation_1-auc:0.64980\tvalidation_1-error:0.36867\n",
      "[21]\tvalidation_0-auc:0.65399\tvalidation_0-error:0.38844\tvalidation_1-auc:0.64988\tvalidation_1-error:0.36864\n",
      "[22]\tvalidation_0-auc:0.65413\tvalidation_0-error:0.38831\tvalidation_1-auc:0.64998\tvalidation_1-error:0.36844\n",
      "[23]\tvalidation_0-auc:0.65429\tvalidation_0-error:0.38820\tvalidation_1-auc:0.64998\tvalidation_1-error:0.36837\n",
      "[24]\tvalidation_0-auc:0.65441\tvalidation_0-error:0.38806\tvalidation_1-auc:0.65006\tvalidation_1-error:0.36822\n",
      "[25]\tvalidation_0-auc:0.65455\tvalidation_0-error:0.38795\tvalidation_1-auc:0.65007\tvalidation_1-error:0.36817\n",
      "[26]\tvalidation_0-auc:0.65466\tvalidation_0-error:0.38793\tvalidation_1-auc:0.65013\tvalidation_1-error:0.36828\n",
      "[27]\tvalidation_0-auc:0.65483\tvalidation_0-error:0.38772\tvalidation_1-auc:0.65019\tvalidation_1-error:0.36836\n",
      "[28]\tvalidation_0-auc:0.65496\tvalidation_0-error:0.38775\tvalidation_1-auc:0.65027\tvalidation_1-error:0.36806\n",
      "[29]\tvalidation_0-auc:0.65514\tvalidation_0-error:0.38762\tvalidation_1-auc:0.65033\tvalidation_1-error:0.36816\n",
      "[30]\tvalidation_0-auc:0.65527\tvalidation_0-error:0.38758\tvalidation_1-auc:0.65036\tvalidation_1-error:0.36799\n",
      "[31]\tvalidation_0-auc:0.65542\tvalidation_0-error:0.38749\tvalidation_1-auc:0.65045\tvalidation_1-error:0.36813\n",
      "[32]\tvalidation_0-auc:0.65552\tvalidation_0-error:0.38718\tvalidation_1-auc:0.65048\tvalidation_1-error:0.36767\n",
      "[33]\tvalidation_0-auc:0.65559\tvalidation_0-error:0.38715\tvalidation_1-auc:0.65049\tvalidation_1-error:0.36806\n",
      "[34]\tvalidation_0-auc:0.65571\tvalidation_0-error:0.38708\tvalidation_1-auc:0.65053\tvalidation_1-error:0.36783\n",
      "[35]\tvalidation_0-auc:0.65578\tvalidation_0-error:0.38703\tvalidation_1-auc:0.65058\tvalidation_1-error:0.36774\n",
      "[36]\tvalidation_0-auc:0.65586\tvalidation_0-error:0.38700\tvalidation_1-auc:0.65055\tvalidation_1-error:0.36766\n",
      "[37]\tvalidation_0-auc:0.65596\tvalidation_0-error:0.38692\tvalidation_1-auc:0.65060\tvalidation_1-error:0.36771\n",
      "[38]\tvalidation_0-auc:0.65614\tvalidation_0-error:0.38647\tvalidation_1-auc:0.65066\tvalidation_1-error:0.36826\n",
      "[39]\tvalidation_0-auc:0.65624\tvalidation_0-error:0.38649\tvalidation_1-auc:0.65070\tvalidation_1-error:0.36856\n",
      "[40]\tvalidation_0-auc:0.65629\tvalidation_0-error:0.38646\tvalidation_1-auc:0.65068\tvalidation_1-error:0.36865\n",
      "[41]\tvalidation_0-auc:0.65638\tvalidation_0-error:0.38626\tvalidation_1-auc:0.65069\tvalidation_1-error:0.36868\n",
      "[42]\tvalidation_0-auc:0.65654\tvalidation_0-error:0.38614\tvalidation_1-auc:0.65075\tvalidation_1-error:0.36870\n",
      "[43]\tvalidation_0-auc:0.65663\tvalidation_0-error:0.38609\tvalidation_1-auc:0.65074\tvalidation_1-error:0.36865\n",
      "[44]\tvalidation_0-auc:0.65670\tvalidation_0-error:0.38604\tvalidation_1-auc:0.65072\tvalidation_1-error:0.36866\n",
      "[45]\tvalidation_0-auc:0.65683\tvalidation_0-error:0.38598\tvalidation_1-auc:0.65076\tvalidation_1-error:0.36870\n",
      "[46]\tvalidation_0-auc:0.65696\tvalidation_0-error:0.38572\tvalidation_1-auc:0.65079\tvalidation_1-error:0.36875\n",
      "[47]\tvalidation_0-auc:0.65704\tvalidation_0-error:0.38567\tvalidation_1-auc:0.65076\tvalidation_1-error:0.36879\n",
      "[48]\tvalidation_0-auc:0.65716\tvalidation_0-error:0.38564\tvalidation_1-auc:0.65081\tvalidation_1-error:0.36878\n",
      "[49]\tvalidation_0-auc:0.65723\tvalidation_0-error:0.38560\tvalidation_1-auc:0.65079\tvalidation_1-error:0.36869\n",
      "[50]\tvalidation_0-auc:0.65737\tvalidation_0-error:0.38568\tvalidation_1-auc:0.65085\tvalidation_1-error:0.36869\n",
      "[51]\tvalidation_0-auc:0.65745\tvalidation_0-error:0.38559\tvalidation_1-auc:0.65083\tvalidation_1-error:0.36869\n",
      "[52]\tvalidation_0-auc:0.65758\tvalidation_0-error:0.38547\tvalidation_1-auc:0.65089\tvalidation_1-error:0.36866\n",
      "[53]\tvalidation_0-auc:0.65765\tvalidation_0-error:0.38547\tvalidation_1-auc:0.65090\tvalidation_1-error:0.36852\n",
      "[54]\tvalidation_0-auc:0.65775\tvalidation_0-error:0.38542\tvalidation_1-auc:0.65093\tvalidation_1-error:0.36867\n",
      "[55]\tvalidation_0-auc:0.65781\tvalidation_0-error:0.38544\tvalidation_1-auc:0.65089\tvalidation_1-error:0.36856\n",
      "[56]\tvalidation_0-auc:0.65791\tvalidation_0-error:0.38538\tvalidation_1-auc:0.65095\tvalidation_1-error:0.36876\n",
      "[57]\tvalidation_0-auc:0.65798\tvalidation_0-error:0.38539\tvalidation_1-auc:0.65096\tvalidation_1-error:0.36867\n",
      "[58]\tvalidation_0-auc:0.65806\tvalidation_0-error:0.38524\tvalidation_1-auc:0.65099\tvalidation_1-error:0.36861\n",
      "[59]\tvalidation_0-auc:0.65815\tvalidation_0-error:0.38521\tvalidation_1-auc:0.65099\tvalidation_1-error:0.36853\n",
      "[60]\tvalidation_0-auc:0.65821\tvalidation_0-error:0.38520\tvalidation_1-auc:0.65101\tvalidation_1-error:0.36863\n",
      "[61]\tvalidation_0-auc:0.65828\tvalidation_0-error:0.38521\tvalidation_1-auc:0.65101\tvalidation_1-error:0.36853\n",
      "[62]\tvalidation_0-auc:0.65837\tvalidation_0-error:0.38508\tvalidation_1-auc:0.65103\tvalidation_1-error:0.36866\n",
      "[63]\tvalidation_0-auc:0.65844\tvalidation_0-error:0.38508\tvalidation_1-auc:0.65106\tvalidation_1-error:0.36861\n",
      "[64]\tvalidation_0-auc:0.65854\tvalidation_0-error:0.38504\tvalidation_1-auc:0.65105\tvalidation_1-error:0.36857\n",
      "[65]\tvalidation_0-auc:0.65863\tvalidation_0-error:0.38501\tvalidation_1-auc:0.65107\tvalidation_1-error:0.36852\n",
      "[66]\tvalidation_0-auc:0.65869\tvalidation_0-error:0.38499\tvalidation_1-auc:0.65109\tvalidation_1-error:0.36844\n",
      "[67]\tvalidation_0-auc:0.65879\tvalidation_0-error:0.38490\tvalidation_1-auc:0.65109\tvalidation_1-error:0.36844\n",
      "[68]\tvalidation_0-auc:0.65887\tvalidation_0-error:0.38485\tvalidation_1-auc:0.65109\tvalidation_1-error:0.36835\n",
      "[69]\tvalidation_0-auc:0.65896\tvalidation_0-error:0.38481\tvalidation_1-auc:0.65108\tvalidation_1-error:0.36829\n",
      "[70]\tvalidation_0-auc:0.65904\tvalidation_0-error:0.38477\tvalidation_1-auc:0.65110\tvalidation_1-error:0.36838\n",
      "[71]\tvalidation_0-auc:0.65910\tvalidation_0-error:0.38478\tvalidation_1-auc:0.65111\tvalidation_1-error:0.36830\n",
      "[72]\tvalidation_0-auc:0.65914\tvalidation_0-error:0.38473\tvalidation_1-auc:0.65114\tvalidation_1-error:0.36832\n",
      "[73]\tvalidation_0-auc:0.65923\tvalidation_0-error:0.38469\tvalidation_1-auc:0.65114\tvalidation_1-error:0.36828\n",
      "[74]\tvalidation_0-auc:0.65926\tvalidation_0-error:0.38466\tvalidation_1-auc:0.65115\tvalidation_1-error:0.36831\n",
      "[75]\tvalidation_0-auc:0.65932\tvalidation_0-error:0.38466\tvalidation_1-auc:0.65117\tvalidation_1-error:0.36824\n",
      "[76]\tvalidation_0-auc:0.65939\tvalidation_0-error:0.38467\tvalidation_1-auc:0.65118\tvalidation_1-error:0.36825\n",
      "[77]\tvalidation_0-auc:0.65947\tvalidation_0-error:0.38461\tvalidation_1-auc:0.65119\tvalidation_1-error:0.36830\n",
      "[78]\tvalidation_0-auc:0.65951\tvalidation_0-error:0.38463\tvalidation_1-auc:0.65119\tvalidation_1-error:0.36822\n",
      "[79]\tvalidation_0-auc:0.65957\tvalidation_0-error:0.38460\tvalidation_1-auc:0.65121\tvalidation_1-error:0.36822\n",
      "[80]\tvalidation_0-auc:0.65965\tvalidation_0-error:0.38456\tvalidation_1-auc:0.65121\tvalidation_1-error:0.36824\n",
      "[81]\tvalidation_0-auc:0.65975\tvalidation_0-error:0.38453\tvalidation_1-auc:0.65122\tvalidation_1-error:0.36813\n",
      "[82]\tvalidation_0-auc:0.65982\tvalidation_0-error:0.38449\tvalidation_1-auc:0.65124\tvalidation_1-error:0.36816\n",
      "[83]\tvalidation_0-auc:0.65985\tvalidation_0-error:0.38448\tvalidation_1-auc:0.65123\tvalidation_1-error:0.36814\n",
      "[84]\tvalidation_0-auc:0.65990\tvalidation_0-error:0.38447\tvalidation_1-auc:0.65123\tvalidation_1-error:0.36803\n",
      "[85]\tvalidation_0-auc:0.65995\tvalidation_0-error:0.38440\tvalidation_1-auc:0.65123\tvalidation_1-error:0.36807\n",
      "[86]\tvalidation_0-auc:0.66000\tvalidation_0-error:0.38438\tvalidation_1-auc:0.65125\tvalidation_1-error:0.36809\n",
      "[87]\tvalidation_0-auc:0.66004\tvalidation_0-error:0.38434\tvalidation_1-auc:0.65124\tvalidation_1-error:0.36811\n",
      "[88]\tvalidation_0-auc:0.66012\tvalidation_0-error:0.38428\tvalidation_1-auc:0.65125\tvalidation_1-error:0.36815\n",
      "[89]\tvalidation_0-auc:0.66016\tvalidation_0-error:0.38427\tvalidation_1-auc:0.65125\tvalidation_1-error:0.36811\n",
      "[90]\tvalidation_0-auc:0.66021\tvalidation_0-error:0.38426\tvalidation_1-auc:0.65126\tvalidation_1-error:0.36807\n",
      "[91]\tvalidation_0-auc:0.66026\tvalidation_0-error:0.38421\tvalidation_1-auc:0.65124\tvalidation_1-error:0.36812\n",
      "[92]\tvalidation_0-auc:0.66030\tvalidation_0-error:0.38421\tvalidation_1-auc:0.65124\tvalidation_1-error:0.36809\n",
      "[93]\tvalidation_0-auc:0.66035\tvalidation_0-error:0.38416\tvalidation_1-auc:0.65125\tvalidation_1-error:0.36810\n",
      "[94]\tvalidation_0-auc:0.66044\tvalidation_0-error:0.38413\tvalidation_1-auc:0.65124\tvalidation_1-error:0.36802\n",
      "[95]\tvalidation_0-auc:0.66049\tvalidation_0-error:0.38402\tvalidation_1-auc:0.65124\tvalidation_1-error:0.36810\n",
      "[96]\tvalidation_0-auc:0.66055\tvalidation_0-error:0.38391\tvalidation_1-auc:0.65127\tvalidation_1-error:0.36804\n",
      "[97]\tvalidation_0-auc:0.66063\tvalidation_0-error:0.38390\tvalidation_1-auc:0.65124\tvalidation_1-error:0.36807\n",
      "[98]\tvalidation_0-auc:0.66068\tvalidation_0-error:0.38387\tvalidation_1-auc:0.65122\tvalidation_1-error:0.36805\n",
      "[99]\tvalidation_0-auc:0.66072\tvalidation_0-error:0.38386\tvalidation_1-auc:0.65123\tvalidation_1-error:0.36806\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 221504, number of negative: 221504\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.925173\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.846594\n",
      "[LightGBM] [Debug] init for col-wise cost 0.015141 seconds, init for row-wise cost 0.016942 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 1124\n",
      "[LightGBM] [Info] Number of data points in the train set: 443008, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 18 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 22 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 23 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 26 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 24 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 29 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 27 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 25 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 21 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 28 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 30 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', learning_rate=0.3, loss='exponential',\n",
       "               max_depth=5, n_estimators=500, random_state=42, verbose=2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grad.fit(X_res, y_res)\n",
    "\n",
    "eval_set = [(X_res, y_res), (X_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]\n",
    "clf_xgb.fit(X_res, y_res, eval_metric=eval_metric, eval_set=eval_set, verbose=True)\n",
    "\n",
    "clf_lgb.fit(X_res, y_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70     55376\n",
      "           1       0.61      0.43      0.51     43709\n",
      "\n",
      "    accuracy                           0.63     99085\n",
      "   macro avg       0.63      0.61      0.61     99085\n",
      "weighted avg       0.63      0.63      0.62     99085\n",
      "\n",
      "------------------------------------------------------------\n",
      "XG Boost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.71     55376\n",
      "           1       0.62      0.43      0.51     43709\n",
      "\n",
      "    accuracy                           0.63     99085\n",
      "   macro avg       0.63      0.61      0.61     99085\n",
      "weighted avg       0.63      0.63      0.62     99085\n",
      "\n",
      "------------------------------------------------------------\n",
      "LightG Boost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.71     55376\n",
      "           1       0.62      0.43      0.51     43709\n",
      "\n",
      "    accuracy                           0.63     99085\n",
      "   macro avg       0.63      0.61      0.61     99085\n",
      "weighted avg       0.63      0.63      0.62     99085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_grad_pred = clf_grad.predict(X_test)   #Verificação com os 3 melhore desempenhos\n",
    "y_xgb_pred = clf_xgb.predict(X_test)\n",
    "y_lgb_pred = clf_lgb.predict(X_test)\n",
    "print(f'Gradient Boost')\n",
    "print(classification_report(y_test, y_grad_pred))\n",
    "print('-'*60)\n",
    "print(f'XG Boost')\n",
    "print(classification_report(y_test, y_xgb_pred))\n",
    "print('-'*60)\n",
    "print(f'LightG Boost')\n",
    "print(classification_report(y_test, y_lgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model      : Decision Tree\n",
      "Accuracy   : 0.6368 \n",
      "Precision  : 0.6338 \n",
      "Recall     : 0.6368 \n",
      "F1 - Score : 0.6267 \n",
      "ROC - AUC  : 0.6181 \n",
      "======================\n",
      "Model      : Random Forest\n",
      "Accuracy   : 0.6363 \n",
      "Precision  : 0.6329 \n",
      "Recall     : 0.6363 \n",
      "F1 - Score : 0.6278 \n",
      "ROC - AUC  : 0.6191 \n",
      "======================\n",
      "Model      : AdaBoost\n",
      "Accuracy   : 0.6214 \n",
      "Precision  : 0.6171 \n",
      "Recall     : 0.6214 \n",
      "F1 - Score : 0.6155 \n",
      "ROC - AUC  : 0.6068 \n",
      "======================\n",
      "Model      : GradientBoosting\n",
      "Accuracy   : 0.6268 \n",
      "Precision  : 0.6227 \n",
      "Recall     : 0.6268 \n",
      "F1 - Score : 0.6184 \n",
      "ROC - AUC  : 0.6097 \n",
      "======================\n",
      "[17:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Model      : XGBoost\n",
      "Accuracy   : 0.6323 \n",
      "Precision  : 0.6291 \n",
      "Recall     : 0.6323 \n",
      "F1 - Score : 0.6214 \n",
      "ROC - AUC  : 0.6130 \n",
      "======================\n",
      "Model      : LightGBM\n",
      "Accuracy   : 0.6303 \n",
      "Precision  : 0.6268 \n",
      "Recall     : 0.6303 \n",
      "F1 - Score : 0.6201 \n",
      "ROC - AUC  : 0.6116 \n",
      "======================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_models_plot_roc_auc_curve(list_models, #Teste com under sample\n",
    "                              \"model_name\",\n",
    "                              \"estimator\",\n",
    "                              X_res2,\n",
    "                              X_test,\n",
    "                              y_res2,\n",
    "                              y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dec_tree = DecisionTreeClassifier(random_state = 42) #Teste com os três melhores desempenhos\n",
    "\n",
    "clf_xgb2 = XGBClassifier (random_state=42,\n",
    "                            n_estimators=250,\n",
    "                            max_depth=7, \n",
    "                            eta=1, \n",
    "                            silent=1,\n",
    "                            objective= 'binary:logistic',\n",
    "                            eval_metric='auc',\n",
    "                            learning_rate=0.05)\n",
    "\n",
    "clf_rand_cl = RandomForestClassifier(random_state = 42,\n",
    "                                        n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-auc:0.64726\tvalidation_0-error:0.39120\tvalidation_1-auc:0.64653\tvalidation_1-error:0.37005\n",
      "[1]\tvalidation_0-auc:0.64788\tvalidation_0-error:0.39067\tvalidation_1-auc:0.64686\tvalidation_1-error:0.37020\n",
      "[2]\tvalidation_0-auc:0.64805\tvalidation_0-error:0.39060\tvalidation_1-auc:0.64730\tvalidation_1-error:0.37010\n",
      "[3]\tvalidation_0-auc:0.64865\tvalidation_0-error:0.39059\tvalidation_1-auc:0.64784\tvalidation_1-error:0.37005\n",
      "[4]\tvalidation_0-auc:0.64861\tvalidation_0-error:0.39072\tvalidation_1-auc:0.64787\tvalidation_1-error:0.36956\n",
      "[5]\tvalidation_0-auc:0.64927\tvalidation_0-error:0.39055\tvalidation_1-auc:0.64849\tvalidation_1-error:0.37001\n",
      "[6]\tvalidation_0-auc:0.64929\tvalidation_0-error:0.39053\tvalidation_1-auc:0.64863\tvalidation_1-error:0.36991\n",
      "[7]\tvalidation_0-auc:0.64975\tvalidation_0-error:0.39043\tvalidation_1-auc:0.64899\tvalidation_1-error:0.36977\n",
      "[8]\tvalidation_0-auc:0.65012\tvalidation_0-error:0.39056\tvalidation_1-auc:0.64932\tvalidation_1-error:0.36926\n",
      "[9]\tvalidation_0-auc:0.65054\tvalidation_0-error:0.39022\tvalidation_1-auc:0.64967\tvalidation_1-error:0.36918\n",
      "[10]\tvalidation_0-auc:0.65067\tvalidation_0-error:0.39019\tvalidation_1-auc:0.64971\tvalidation_1-error:0.36963\n",
      "[11]\tvalidation_0-auc:0.65083\tvalidation_0-error:0.39023\tvalidation_1-auc:0.64979\tvalidation_1-error:0.36973\n",
      "[12]\tvalidation_0-auc:0.65114\tvalidation_0-error:0.39014\tvalidation_1-auc:0.65000\tvalidation_1-error:0.36930\n",
      "[13]\tvalidation_0-auc:0.65121\tvalidation_0-error:0.39013\tvalidation_1-auc:0.65008\tvalidation_1-error:0.36957\n",
      "[14]\tvalidation_0-auc:0.65130\tvalidation_0-error:0.39003\tvalidation_1-auc:0.65019\tvalidation_1-error:0.36937\n",
      "[15]\tvalidation_0-auc:0.65138\tvalidation_0-error:0.38999\tvalidation_1-auc:0.65026\tvalidation_1-error:0.36924\n",
      "[16]\tvalidation_0-auc:0.65156\tvalidation_0-error:0.38996\tvalidation_1-auc:0.65047\tvalidation_1-error:0.36922\n",
      "[17]\tvalidation_0-auc:0.65167\tvalidation_0-error:0.38992\tvalidation_1-auc:0.65063\tvalidation_1-error:0.36886\n",
      "[18]\tvalidation_0-auc:0.65173\tvalidation_0-error:0.38989\tvalidation_1-auc:0.65055\tvalidation_1-error:0.36902\n",
      "[19]\tvalidation_0-auc:0.65191\tvalidation_0-error:0.38984\tvalidation_1-auc:0.65061\tvalidation_1-error:0.36914\n",
      "[20]\tvalidation_0-auc:0.65204\tvalidation_0-error:0.38978\tvalidation_1-auc:0.65074\tvalidation_1-error:0.36925\n",
      "[21]\tvalidation_0-auc:0.65216\tvalidation_0-error:0.38975\tvalidation_1-auc:0.65085\tvalidation_1-error:0.36946\n",
      "[22]\tvalidation_0-auc:0.65229\tvalidation_0-error:0.38977\tvalidation_1-auc:0.65093\tvalidation_1-error:0.36924\n",
      "[23]\tvalidation_0-auc:0.65239\tvalidation_0-error:0.38968\tvalidation_1-auc:0.65111\tvalidation_1-error:0.36875\n",
      "[24]\tvalidation_0-auc:0.65253\tvalidation_0-error:0.38966\tvalidation_1-auc:0.65122\tvalidation_1-error:0.36915\n",
      "[25]\tvalidation_0-auc:0.65260\tvalidation_0-error:0.38967\tvalidation_1-auc:0.65131\tvalidation_1-error:0.36892\n",
      "[26]\tvalidation_0-auc:0.65270\tvalidation_0-error:0.38935\tvalidation_1-auc:0.65142\tvalidation_1-error:0.36884\n",
      "[27]\tvalidation_0-auc:0.65281\tvalidation_0-error:0.38921\tvalidation_1-auc:0.65143\tvalidation_1-error:0.36889\n",
      "[28]\tvalidation_0-auc:0.65288\tvalidation_0-error:0.38931\tvalidation_1-auc:0.65152\tvalidation_1-error:0.36866\n",
      "[29]\tvalidation_0-auc:0.65299\tvalidation_0-error:0.38920\tvalidation_1-auc:0.65161\tvalidation_1-error:0.36867\n",
      "[30]\tvalidation_0-auc:0.65306\tvalidation_0-error:0.38910\tvalidation_1-auc:0.65167\tvalidation_1-error:0.36884\n",
      "[31]\tvalidation_0-auc:0.65313\tvalidation_0-error:0.38887\tvalidation_1-auc:0.65174\tvalidation_1-error:0.36851\n",
      "[32]\tvalidation_0-auc:0.65324\tvalidation_0-error:0.38871\tvalidation_1-auc:0.65182\tvalidation_1-error:0.36857\n",
      "[33]\tvalidation_0-auc:0.65332\tvalidation_0-error:0.38857\tvalidation_1-auc:0.65192\tvalidation_1-error:0.36840\n",
      "[34]\tvalidation_0-auc:0.65336\tvalidation_0-error:0.38849\tvalidation_1-auc:0.65192\tvalidation_1-error:0.36855\n",
      "[35]\tvalidation_0-auc:0.65344\tvalidation_0-error:0.38836\tvalidation_1-auc:0.65197\tvalidation_1-error:0.36866\n",
      "[36]\tvalidation_0-auc:0.65354\tvalidation_0-error:0.38825\tvalidation_1-auc:0.65204\tvalidation_1-error:0.36876\n",
      "[37]\tvalidation_0-auc:0.65361\tvalidation_0-error:0.38815\tvalidation_1-auc:0.65207\tvalidation_1-error:0.36867\n",
      "[38]\tvalidation_0-auc:0.65368\tvalidation_0-error:0.38814\tvalidation_1-auc:0.65213\tvalidation_1-error:0.36861\n",
      "[39]\tvalidation_0-auc:0.65375\tvalidation_0-error:0.38815\tvalidation_1-auc:0.65217\tvalidation_1-error:0.36883\n",
      "[40]\tvalidation_0-auc:0.65380\tvalidation_0-error:0.38815\tvalidation_1-auc:0.65222\tvalidation_1-error:0.36872\n",
      "[41]\tvalidation_0-auc:0.65388\tvalidation_0-error:0.38808\tvalidation_1-auc:0.65227\tvalidation_1-error:0.36834\n",
      "[42]\tvalidation_0-auc:0.65394\tvalidation_0-error:0.38803\tvalidation_1-auc:0.65235\tvalidation_1-error:0.36862\n",
      "[43]\tvalidation_0-auc:0.65402\tvalidation_0-error:0.38789\tvalidation_1-auc:0.65241\tvalidation_1-error:0.36864\n",
      "[44]\tvalidation_0-auc:0.65410\tvalidation_0-error:0.38797\tvalidation_1-auc:0.65246\tvalidation_1-error:0.36864\n",
      "[45]\tvalidation_0-auc:0.65416\tvalidation_0-error:0.38792\tvalidation_1-auc:0.65251\tvalidation_1-error:0.36868\n",
      "[46]\tvalidation_0-auc:0.65420\tvalidation_0-error:0.38786\tvalidation_1-auc:0.65250\tvalidation_1-error:0.36840\n",
      "[47]\tvalidation_0-auc:0.65426\tvalidation_0-error:0.38783\tvalidation_1-auc:0.65255\tvalidation_1-error:0.36861\n",
      "[48]\tvalidation_0-auc:0.65433\tvalidation_0-error:0.38780\tvalidation_1-auc:0.65263\tvalidation_1-error:0.36853\n",
      "[49]\tvalidation_0-auc:0.65442\tvalidation_0-error:0.38776\tvalidation_1-auc:0.65267\tvalidation_1-error:0.36852\n",
      "[50]\tvalidation_0-auc:0.65447\tvalidation_0-error:0.38773\tvalidation_1-auc:0.65269\tvalidation_1-error:0.36850\n",
      "[51]\tvalidation_0-auc:0.65454\tvalidation_0-error:0.38770\tvalidation_1-auc:0.65272\tvalidation_1-error:0.36836\n",
      "[52]\tvalidation_0-auc:0.65461\tvalidation_0-error:0.38768\tvalidation_1-auc:0.65277\tvalidation_1-error:0.36843\n",
      "[53]\tvalidation_0-auc:0.65466\tvalidation_0-error:0.38766\tvalidation_1-auc:0.65278\tvalidation_1-error:0.36840\n",
      "[54]\tvalidation_0-auc:0.65472\tvalidation_0-error:0.38765\tvalidation_1-auc:0.65285\tvalidation_1-error:0.36816\n",
      "[55]\tvalidation_0-auc:0.65480\tvalidation_0-error:0.38760\tvalidation_1-auc:0.65293\tvalidation_1-error:0.36831\n",
      "[56]\tvalidation_0-auc:0.65484\tvalidation_0-error:0.38760\tvalidation_1-auc:0.65295\tvalidation_1-error:0.36827\n",
      "[57]\tvalidation_0-auc:0.65492\tvalidation_0-error:0.38759\tvalidation_1-auc:0.65302\tvalidation_1-error:0.36814\n",
      "[58]\tvalidation_0-auc:0.65498\tvalidation_0-error:0.38753\tvalidation_1-auc:0.65307\tvalidation_1-error:0.36803\n",
      "[59]\tvalidation_0-auc:0.65505\tvalidation_0-error:0.38750\tvalidation_1-auc:0.65314\tvalidation_1-error:0.36794\n",
      "[60]\tvalidation_0-auc:0.65510\tvalidation_0-error:0.38746\tvalidation_1-auc:0.65318\tvalidation_1-error:0.36793\n",
      "[61]\tvalidation_0-auc:0.65518\tvalidation_0-error:0.38742\tvalidation_1-auc:0.65324\tvalidation_1-error:0.36791\n",
      "[62]\tvalidation_0-auc:0.65523\tvalidation_0-error:0.38738\tvalidation_1-auc:0.65328\tvalidation_1-error:0.36793\n",
      "[63]\tvalidation_0-auc:0.65529\tvalidation_0-error:0.38736\tvalidation_1-auc:0.65333\tvalidation_1-error:0.36799\n",
      "[64]\tvalidation_0-auc:0.65534\tvalidation_0-error:0.38734\tvalidation_1-auc:0.65336\tvalidation_1-error:0.36788\n",
      "[65]\tvalidation_0-auc:0.65538\tvalidation_0-error:0.38731\tvalidation_1-auc:0.65339\tvalidation_1-error:0.36794\n",
      "[66]\tvalidation_0-auc:0.65545\tvalidation_0-error:0.38726\tvalidation_1-auc:0.65345\tvalidation_1-error:0.36790\n",
      "[67]\tvalidation_0-auc:0.65550\tvalidation_0-error:0.38725\tvalidation_1-auc:0.65346\tvalidation_1-error:0.36794\n",
      "[68]\tvalidation_0-auc:0.65557\tvalidation_0-error:0.38720\tvalidation_1-auc:0.65351\tvalidation_1-error:0.36785\n",
      "[69]\tvalidation_0-auc:0.65561\tvalidation_0-error:0.38720\tvalidation_1-auc:0.65354\tvalidation_1-error:0.36779\n",
      "[70]\tvalidation_0-auc:0.65566\tvalidation_0-error:0.38714\tvalidation_1-auc:0.65359\tvalidation_1-error:0.36773\n",
      "[71]\tvalidation_0-auc:0.65569\tvalidation_0-error:0.38715\tvalidation_1-auc:0.65362\tvalidation_1-error:0.36782\n",
      "[72]\tvalidation_0-auc:0.65573\tvalidation_0-error:0.38714\tvalidation_1-auc:0.65365\tvalidation_1-error:0.36772\n",
      "[73]\tvalidation_0-auc:0.65579\tvalidation_0-error:0.38707\tvalidation_1-auc:0.65368\tvalidation_1-error:0.36777\n",
      "[74]\tvalidation_0-auc:0.65583\tvalidation_0-error:0.38707\tvalidation_1-auc:0.65370\tvalidation_1-error:0.36778\n",
      "[75]\tvalidation_0-auc:0.65588\tvalidation_0-error:0.38704\tvalidation_1-auc:0.65374\tvalidation_1-error:0.36775\n",
      "[76]\tvalidation_0-auc:0.65594\tvalidation_0-error:0.38698\tvalidation_1-auc:0.65381\tvalidation_1-error:0.36780\n",
      "[77]\tvalidation_0-auc:0.65596\tvalidation_0-error:0.38697\tvalidation_1-auc:0.65382\tvalidation_1-error:0.36777\n",
      "[78]\tvalidation_0-auc:0.65601\tvalidation_0-error:0.38696\tvalidation_1-auc:0.65387\tvalidation_1-error:0.36782\n",
      "[79]\tvalidation_0-auc:0.65603\tvalidation_0-error:0.38697\tvalidation_1-auc:0.65391\tvalidation_1-error:0.36792\n",
      "[80]\tvalidation_0-auc:0.65609\tvalidation_0-error:0.38690\tvalidation_1-auc:0.65393\tvalidation_1-error:0.36778\n",
      "[81]\tvalidation_0-auc:0.65611\tvalidation_0-error:0.38691\tvalidation_1-auc:0.65398\tvalidation_1-error:0.36782\n",
      "[82]\tvalidation_0-auc:0.65614\tvalidation_0-error:0.38690\tvalidation_1-auc:0.65400\tvalidation_1-error:0.36778\n",
      "[83]\tvalidation_0-auc:0.65617\tvalidation_0-error:0.38694\tvalidation_1-auc:0.65402\tvalidation_1-error:0.36773\n",
      "[84]\tvalidation_0-auc:0.65621\tvalidation_0-error:0.38690\tvalidation_1-auc:0.65405\tvalidation_1-error:0.36773\n",
      "[85]\tvalidation_0-auc:0.65624\tvalidation_0-error:0.38689\tvalidation_1-auc:0.65406\tvalidation_1-error:0.36771\n",
      "[86]\tvalidation_0-auc:0.65627\tvalidation_0-error:0.38687\tvalidation_1-auc:0.65409\tvalidation_1-error:0.36769\n",
      "[87]\tvalidation_0-auc:0.65633\tvalidation_0-error:0.38684\tvalidation_1-auc:0.65414\tvalidation_1-error:0.36756\n",
      "[88]\tvalidation_0-auc:0.65636\tvalidation_0-error:0.38682\tvalidation_1-auc:0.65416\tvalidation_1-error:0.36752\n",
      "[89]\tvalidation_0-auc:0.65641\tvalidation_0-error:0.38680\tvalidation_1-auc:0.65418\tvalidation_1-error:0.36758\n",
      "[90]\tvalidation_0-auc:0.65646\tvalidation_0-error:0.38673\tvalidation_1-auc:0.65421\tvalidation_1-error:0.36745\n",
      "[91]\tvalidation_0-auc:0.65650\tvalidation_0-error:0.38667\tvalidation_1-auc:0.65421\tvalidation_1-error:0.36765\n",
      "[92]\tvalidation_0-auc:0.65655\tvalidation_0-error:0.38664\tvalidation_1-auc:0.65426\tvalidation_1-error:0.36763\n",
      "[93]\tvalidation_0-auc:0.65657\tvalidation_0-error:0.38661\tvalidation_1-auc:0.65426\tvalidation_1-error:0.36762\n",
      "[94]\tvalidation_0-auc:0.65661\tvalidation_0-error:0.38656\tvalidation_1-auc:0.65429\tvalidation_1-error:0.36754\n",
      "[95]\tvalidation_0-auc:0.65665\tvalidation_0-error:0.38658\tvalidation_1-auc:0.65431\tvalidation_1-error:0.36757\n",
      "[96]\tvalidation_0-auc:0.65666\tvalidation_0-error:0.38657\tvalidation_1-auc:0.65430\tvalidation_1-error:0.36758\n",
      "[97]\tvalidation_0-auc:0.65669\tvalidation_0-error:0.38656\tvalidation_1-auc:0.65433\tvalidation_1-error:0.36751\n",
      "[98]\tvalidation_0-auc:0.65673\tvalidation_0-error:0.38653\tvalidation_1-auc:0.65435\tvalidation_1-error:0.36745\n",
      "[99]\tvalidation_0-auc:0.65675\tvalidation_0-error:0.38655\tvalidation_1-auc:0.65436\tvalidation_1-error:0.36747\n",
      "[100]\tvalidation_0-auc:0.65680\tvalidation_0-error:0.38649\tvalidation_1-auc:0.65439\tvalidation_1-error:0.36737\n",
      "[101]\tvalidation_0-auc:0.65682\tvalidation_0-error:0.38649\tvalidation_1-auc:0.65441\tvalidation_1-error:0.36742\n",
      "[102]\tvalidation_0-auc:0.65685\tvalidation_0-error:0.38645\tvalidation_1-auc:0.65442\tvalidation_1-error:0.36739\n",
      "[103]\tvalidation_0-auc:0.65689\tvalidation_0-error:0.38640\tvalidation_1-auc:0.65443\tvalidation_1-error:0.36734\n",
      "[104]\tvalidation_0-auc:0.65693\tvalidation_0-error:0.38639\tvalidation_1-auc:0.65446\tvalidation_1-error:0.36735\n",
      "[105]\tvalidation_0-auc:0.65696\tvalidation_0-error:0.38633\tvalidation_1-auc:0.65448\tvalidation_1-error:0.36737\n",
      "[106]\tvalidation_0-auc:0.65703\tvalidation_0-error:0.38630\tvalidation_1-auc:0.65450\tvalidation_1-error:0.36738\n",
      "[107]\tvalidation_0-auc:0.65705\tvalidation_0-error:0.38628\tvalidation_1-auc:0.65449\tvalidation_1-error:0.36739\n",
      "[108]\tvalidation_0-auc:0.65708\tvalidation_0-error:0.38623\tvalidation_1-auc:0.65455\tvalidation_1-error:0.36739\n",
      "[109]\tvalidation_0-auc:0.65713\tvalidation_0-error:0.38617\tvalidation_1-auc:0.65458\tvalidation_1-error:0.36732\n",
      "[110]\tvalidation_0-auc:0.65715\tvalidation_0-error:0.38617\tvalidation_1-auc:0.65460\tvalidation_1-error:0.36735\n",
      "[111]\tvalidation_0-auc:0.65719\tvalidation_0-error:0.38618\tvalidation_1-auc:0.65463\tvalidation_1-error:0.36733\n",
      "[112]\tvalidation_0-auc:0.65721\tvalidation_0-error:0.38617\tvalidation_1-auc:0.65464\tvalidation_1-error:0.36734\n",
      "[113]\tvalidation_0-auc:0.65723\tvalidation_0-error:0.38615\tvalidation_1-auc:0.65465\tvalidation_1-error:0.36732\n",
      "[114]\tvalidation_0-auc:0.65726\tvalidation_0-error:0.38611\tvalidation_1-auc:0.65466\tvalidation_1-error:0.36733\n",
      "[115]\tvalidation_0-auc:0.65728\tvalidation_0-error:0.38614\tvalidation_1-auc:0.65467\tvalidation_1-error:0.36733\n",
      "[116]\tvalidation_0-auc:0.65732\tvalidation_0-error:0.38610\tvalidation_1-auc:0.65471\tvalidation_1-error:0.36733\n",
      "[117]\tvalidation_0-auc:0.65735\tvalidation_0-error:0.38606\tvalidation_1-auc:0.65472\tvalidation_1-error:0.36729\n",
      "[118]\tvalidation_0-auc:0.65736\tvalidation_0-error:0.38605\tvalidation_1-auc:0.65473\tvalidation_1-error:0.36730\n",
      "[119]\tvalidation_0-auc:0.65739\tvalidation_0-error:0.38603\tvalidation_1-auc:0.65473\tvalidation_1-error:0.36734\n",
      "[120]\tvalidation_0-auc:0.65742\tvalidation_0-error:0.38600\tvalidation_1-auc:0.65477\tvalidation_1-error:0.36731\n",
      "[121]\tvalidation_0-auc:0.65744\tvalidation_0-error:0.38600\tvalidation_1-auc:0.65477\tvalidation_1-error:0.36734\n",
      "[122]\tvalidation_0-auc:0.65747\tvalidation_0-error:0.38599\tvalidation_1-auc:0.65478\tvalidation_1-error:0.36729\n",
      "[123]\tvalidation_0-auc:0.65749\tvalidation_0-error:0.38598\tvalidation_1-auc:0.65479\tvalidation_1-error:0.36728\n",
      "[124]\tvalidation_0-auc:0.65750\tvalidation_0-error:0.38600\tvalidation_1-auc:0.65477\tvalidation_1-error:0.36727\n",
      "[125]\tvalidation_0-auc:0.65753\tvalidation_0-error:0.38595\tvalidation_1-auc:0.65479\tvalidation_1-error:0.36727\n",
      "[126]\tvalidation_0-auc:0.65756\tvalidation_0-error:0.38595\tvalidation_1-auc:0.65484\tvalidation_1-error:0.36726\n",
      "[127]\tvalidation_0-auc:0.65758\tvalidation_0-error:0.38593\tvalidation_1-auc:0.65485\tvalidation_1-error:0.36721\n",
      "[128]\tvalidation_0-auc:0.65760\tvalidation_0-error:0.38590\tvalidation_1-auc:0.65487\tvalidation_1-error:0.36719\n",
      "[129]\tvalidation_0-auc:0.65762\tvalidation_0-error:0.38589\tvalidation_1-auc:0.65486\tvalidation_1-error:0.36716\n",
      "[130]\tvalidation_0-auc:0.65767\tvalidation_0-error:0.38579\tvalidation_1-auc:0.65488\tvalidation_1-error:0.36713\n",
      "[131]\tvalidation_0-auc:0.65769\tvalidation_0-error:0.38576\tvalidation_1-auc:0.65489\tvalidation_1-error:0.36722\n",
      "[132]\tvalidation_0-auc:0.65770\tvalidation_0-error:0.38577\tvalidation_1-auc:0.65489\tvalidation_1-error:0.36723\n",
      "[133]\tvalidation_0-auc:0.65774\tvalidation_0-error:0.38575\tvalidation_1-auc:0.65492\tvalidation_1-error:0.36717\n",
      "[134]\tvalidation_0-auc:0.65775\tvalidation_0-error:0.38574\tvalidation_1-auc:0.65492\tvalidation_1-error:0.36718\n",
      "[135]\tvalidation_0-auc:0.65778\tvalidation_0-error:0.38574\tvalidation_1-auc:0.65494\tvalidation_1-error:0.36718\n",
      "[136]\tvalidation_0-auc:0.65781\tvalidation_0-error:0.38570\tvalidation_1-auc:0.65495\tvalidation_1-error:0.36714\n",
      "[137]\tvalidation_0-auc:0.65785\tvalidation_0-error:0.38570\tvalidation_1-auc:0.65497\tvalidation_1-error:0.36713\n",
      "[138]\tvalidation_0-auc:0.65787\tvalidation_0-error:0.38570\tvalidation_1-auc:0.65497\tvalidation_1-error:0.36715\n",
      "[139]\tvalidation_0-auc:0.65791\tvalidation_0-error:0.38566\tvalidation_1-auc:0.65497\tvalidation_1-error:0.36709\n",
      "[140]\tvalidation_0-auc:0.65793\tvalidation_0-error:0.38564\tvalidation_1-auc:0.65498\tvalidation_1-error:0.36710\n",
      "[141]\tvalidation_0-auc:0.65797\tvalidation_0-error:0.38566\tvalidation_1-auc:0.65499\tvalidation_1-error:0.36705\n",
      "[142]\tvalidation_0-auc:0.65799\tvalidation_0-error:0.38564\tvalidation_1-auc:0.65501\tvalidation_1-error:0.36704\n",
      "[143]\tvalidation_0-auc:0.65803\tvalidation_0-error:0.38562\tvalidation_1-auc:0.65503\tvalidation_1-error:0.36708\n",
      "[144]\tvalidation_0-auc:0.65805\tvalidation_0-error:0.38561\tvalidation_1-auc:0.65505\tvalidation_1-error:0.36707\n",
      "[145]\tvalidation_0-auc:0.65808\tvalidation_0-error:0.38560\tvalidation_1-auc:0.65507\tvalidation_1-error:0.36710\n",
      "[146]\tvalidation_0-auc:0.65809\tvalidation_0-error:0.38559\tvalidation_1-auc:0.65507\tvalidation_1-error:0.36710\n",
      "[147]\tvalidation_0-auc:0.65813\tvalidation_0-error:0.38553\tvalidation_1-auc:0.65508\tvalidation_1-error:0.36709\n",
      "[148]\tvalidation_0-auc:0.65817\tvalidation_0-error:0.38555\tvalidation_1-auc:0.65510\tvalidation_1-error:0.36707\n",
      "[149]\tvalidation_0-auc:0.65818\tvalidation_0-error:0.38555\tvalidation_1-auc:0.65510\tvalidation_1-error:0.36706\n",
      "[150]\tvalidation_0-auc:0.65821\tvalidation_0-error:0.38557\tvalidation_1-auc:0.65512\tvalidation_1-error:0.36709\n",
      "[151]\tvalidation_0-auc:0.65823\tvalidation_0-error:0.38556\tvalidation_1-auc:0.65512\tvalidation_1-error:0.36709\n",
      "[152]\tvalidation_0-auc:0.65826\tvalidation_0-error:0.38556\tvalidation_1-auc:0.65516\tvalidation_1-error:0.36717\n",
      "[153]\tvalidation_0-auc:0.65827\tvalidation_0-error:0.38552\tvalidation_1-auc:0.65515\tvalidation_1-error:0.36721\n",
      "[154]\tvalidation_0-auc:0.65832\tvalidation_0-error:0.38556\tvalidation_1-auc:0.65518\tvalidation_1-error:0.36724\n",
      "[155]\tvalidation_0-auc:0.65835\tvalidation_0-error:0.38555\tvalidation_1-auc:0.65519\tvalidation_1-error:0.36724\n",
      "[156]\tvalidation_0-auc:0.65838\tvalidation_0-error:0.38554\tvalidation_1-auc:0.65521\tvalidation_1-error:0.36722\n",
      "[157]\tvalidation_0-auc:0.65841\tvalidation_0-error:0.38551\tvalidation_1-auc:0.65523\tvalidation_1-error:0.36719\n",
      "[158]\tvalidation_0-auc:0.65842\tvalidation_0-error:0.38550\tvalidation_1-auc:0.65523\tvalidation_1-error:0.36722\n",
      "[159]\tvalidation_0-auc:0.65844\tvalidation_0-error:0.38550\tvalidation_1-auc:0.65523\tvalidation_1-error:0.36723\n",
      "[160]\tvalidation_0-auc:0.65845\tvalidation_0-error:0.38549\tvalidation_1-auc:0.65524\tvalidation_1-error:0.36723\n",
      "[161]\tvalidation_0-auc:0.65849\tvalidation_0-error:0.38551\tvalidation_1-auc:0.65526\tvalidation_1-error:0.36720\n",
      "[162]\tvalidation_0-auc:0.65852\tvalidation_0-error:0.38545\tvalidation_1-auc:0.65526\tvalidation_1-error:0.36725\n",
      "[163]\tvalidation_0-auc:0.65855\tvalidation_0-error:0.38544\tvalidation_1-auc:0.65527\tvalidation_1-error:0.36730\n",
      "[164]\tvalidation_0-auc:0.65858\tvalidation_0-error:0.38543\tvalidation_1-auc:0.65527\tvalidation_1-error:0.36732\n",
      "[165]\tvalidation_0-auc:0.65859\tvalidation_0-error:0.38541\tvalidation_1-auc:0.65528\tvalidation_1-error:0.36727\n",
      "[166]\tvalidation_0-auc:0.65862\tvalidation_0-error:0.38537\tvalidation_1-auc:0.65529\tvalidation_1-error:0.36729\n",
      "[167]\tvalidation_0-auc:0.65865\tvalidation_0-error:0.38538\tvalidation_1-auc:0.65529\tvalidation_1-error:0.36722\n",
      "[168]\tvalidation_0-auc:0.65868\tvalidation_0-error:0.38535\tvalidation_1-auc:0.65528\tvalidation_1-error:0.36726\n",
      "[169]\tvalidation_0-auc:0.65870\tvalidation_0-error:0.38531\tvalidation_1-auc:0.65529\tvalidation_1-error:0.36731\n",
      "[170]\tvalidation_0-auc:0.65870\tvalidation_0-error:0.38531\tvalidation_1-auc:0.65530\tvalidation_1-error:0.36733\n",
      "[171]\tvalidation_0-auc:0.65874\tvalidation_0-error:0.38524\tvalidation_1-auc:0.65531\tvalidation_1-error:0.36723\n",
      "[172]\tvalidation_0-auc:0.65877\tvalidation_0-error:0.38521\tvalidation_1-auc:0.65533\tvalidation_1-error:0.36721\n",
      "[173]\tvalidation_0-auc:0.65880\tvalidation_0-error:0.38520\tvalidation_1-auc:0.65533\tvalidation_1-error:0.36726\n",
      "[174]\tvalidation_0-auc:0.65882\tvalidation_0-error:0.38517\tvalidation_1-auc:0.65533\tvalidation_1-error:0.36734\n",
      "[175]\tvalidation_0-auc:0.65884\tvalidation_0-error:0.38517\tvalidation_1-auc:0.65533\tvalidation_1-error:0.36731\n",
      "[176]\tvalidation_0-auc:0.65887\tvalidation_0-error:0.38516\tvalidation_1-auc:0.65534\tvalidation_1-error:0.36734\n",
      "[177]\tvalidation_0-auc:0.65889\tvalidation_0-error:0.38514\tvalidation_1-auc:0.65534\tvalidation_1-error:0.36734\n",
      "[178]\tvalidation_0-auc:0.65890\tvalidation_0-error:0.38514\tvalidation_1-auc:0.65535\tvalidation_1-error:0.36733\n",
      "[179]\tvalidation_0-auc:0.65891\tvalidation_0-error:0.38514\tvalidation_1-auc:0.65535\tvalidation_1-error:0.36734\n",
      "[180]\tvalidation_0-auc:0.65894\tvalidation_0-error:0.38512\tvalidation_1-auc:0.65537\tvalidation_1-error:0.36736\n",
      "[181]\tvalidation_0-auc:0.65897\tvalidation_0-error:0.38512\tvalidation_1-auc:0.65537\tvalidation_1-error:0.36734\n",
      "[182]\tvalidation_0-auc:0.65898\tvalidation_0-error:0.38511\tvalidation_1-auc:0.65539\tvalidation_1-error:0.36732\n",
      "[183]\tvalidation_0-auc:0.65901\tvalidation_0-error:0.38511\tvalidation_1-auc:0.65540\tvalidation_1-error:0.36732\n",
      "[184]\tvalidation_0-auc:0.65903\tvalidation_0-error:0.38511\tvalidation_1-auc:0.65542\tvalidation_1-error:0.36721\n",
      "[185]\tvalidation_0-auc:0.65905\tvalidation_0-error:0.38510\tvalidation_1-auc:0.65541\tvalidation_1-error:0.36728\n",
      "[186]\tvalidation_0-auc:0.65905\tvalidation_0-error:0.38509\tvalidation_1-auc:0.65541\tvalidation_1-error:0.36729\n",
      "[187]\tvalidation_0-auc:0.65907\tvalidation_0-error:0.38508\tvalidation_1-auc:0.65542\tvalidation_1-error:0.36726\n",
      "[188]\tvalidation_0-auc:0.65908\tvalidation_0-error:0.38508\tvalidation_1-auc:0.65542\tvalidation_1-error:0.36725\n",
      "[189]\tvalidation_0-auc:0.65911\tvalidation_0-error:0.38502\tvalidation_1-auc:0.65544\tvalidation_1-error:0.36719\n",
      "[190]\tvalidation_0-auc:0.65912\tvalidation_0-error:0.38499\tvalidation_1-auc:0.65544\tvalidation_1-error:0.36720\n",
      "[191]\tvalidation_0-auc:0.65913\tvalidation_0-error:0.38499\tvalidation_1-auc:0.65544\tvalidation_1-error:0.36723\n",
      "[192]\tvalidation_0-auc:0.65913\tvalidation_0-error:0.38499\tvalidation_1-auc:0.65545\tvalidation_1-error:0.36723\n",
      "[193]\tvalidation_0-auc:0.65914\tvalidation_0-error:0.38497\tvalidation_1-auc:0.65545\tvalidation_1-error:0.36727\n",
      "[194]\tvalidation_0-auc:0.65916\tvalidation_0-error:0.38498\tvalidation_1-auc:0.65546\tvalidation_1-error:0.36725\n",
      "[195]\tvalidation_0-auc:0.65919\tvalidation_0-error:0.38494\tvalidation_1-auc:0.65547\tvalidation_1-error:0.36723\n",
      "[196]\tvalidation_0-auc:0.65921\tvalidation_0-error:0.38497\tvalidation_1-auc:0.65548\tvalidation_1-error:0.36721\n",
      "[197]\tvalidation_0-auc:0.65922\tvalidation_0-error:0.38496\tvalidation_1-auc:0.65548\tvalidation_1-error:0.36720\n",
      "[198]\tvalidation_0-auc:0.65925\tvalidation_0-error:0.38495\tvalidation_1-auc:0.65550\tvalidation_1-error:0.36720\n",
      "[199]\tvalidation_0-auc:0.65925\tvalidation_0-error:0.38495\tvalidation_1-auc:0.65550\tvalidation_1-error:0.36720\n",
      "[200]\tvalidation_0-auc:0.65927\tvalidation_0-error:0.38493\tvalidation_1-auc:0.65549\tvalidation_1-error:0.36723\n",
      "[201]\tvalidation_0-auc:0.65928\tvalidation_0-error:0.38493\tvalidation_1-auc:0.65550\tvalidation_1-error:0.36720\n",
      "[202]\tvalidation_0-auc:0.65929\tvalidation_0-error:0.38492\tvalidation_1-auc:0.65551\tvalidation_1-error:0.36718\n",
      "[203]\tvalidation_0-auc:0.65932\tvalidation_0-error:0.38490\tvalidation_1-auc:0.65552\tvalidation_1-error:0.36720\n",
      "[204]\tvalidation_0-auc:0.65934\tvalidation_0-error:0.38486\tvalidation_1-auc:0.65553\tvalidation_1-error:0.36713\n",
      "[205]\tvalidation_0-auc:0.65936\tvalidation_0-error:0.38484\tvalidation_1-auc:0.65554\tvalidation_1-error:0.36716\n",
      "[206]\tvalidation_0-auc:0.65939\tvalidation_0-error:0.38484\tvalidation_1-auc:0.65556\tvalidation_1-error:0.36713\n",
      "[207]\tvalidation_0-auc:0.65939\tvalidation_0-error:0.38483\tvalidation_1-auc:0.65555\tvalidation_1-error:0.36715\n",
      "[208]\tvalidation_0-auc:0.65940\tvalidation_0-error:0.38484\tvalidation_1-auc:0.65556\tvalidation_1-error:0.36715\n",
      "[209]\tvalidation_0-auc:0.65942\tvalidation_0-error:0.38480\tvalidation_1-auc:0.65556\tvalidation_1-error:0.36722\n",
      "[210]\tvalidation_0-auc:0.65943\tvalidation_0-error:0.38480\tvalidation_1-auc:0.65556\tvalidation_1-error:0.36720\n",
      "[211]\tvalidation_0-auc:0.65946\tvalidation_0-error:0.38478\tvalidation_1-auc:0.65557\tvalidation_1-error:0.36724\n",
      "[212]\tvalidation_0-auc:0.65948\tvalidation_0-error:0.38479\tvalidation_1-auc:0.65559\tvalidation_1-error:0.36717\n",
      "[213]\tvalidation_0-auc:0.65949\tvalidation_0-error:0.38479\tvalidation_1-auc:0.65559\tvalidation_1-error:0.36718\n",
      "[214]\tvalidation_0-auc:0.65953\tvalidation_0-error:0.38475\tvalidation_1-auc:0.65561\tvalidation_1-error:0.36717\n",
      "[215]\tvalidation_0-auc:0.65955\tvalidation_0-error:0.38472\tvalidation_1-auc:0.65561\tvalidation_1-error:0.36713\n",
      "[216]\tvalidation_0-auc:0.65958\tvalidation_0-error:0.38467\tvalidation_1-auc:0.65561\tvalidation_1-error:0.36711\n",
      "[217]\tvalidation_0-auc:0.65960\tvalidation_0-error:0.38464\tvalidation_1-auc:0.65562\tvalidation_1-error:0.36714\n",
      "[218]\tvalidation_0-auc:0.65961\tvalidation_0-error:0.38466\tvalidation_1-auc:0.65563\tvalidation_1-error:0.36711\n",
      "[219]\tvalidation_0-auc:0.65964\tvalidation_0-error:0.38464\tvalidation_1-auc:0.65563\tvalidation_1-error:0.36712\n",
      "[220]\tvalidation_0-auc:0.65966\tvalidation_0-error:0.38459\tvalidation_1-auc:0.65565\tvalidation_1-error:0.36711\n",
      "[221]\tvalidation_0-auc:0.65968\tvalidation_0-error:0.38455\tvalidation_1-auc:0.65565\tvalidation_1-error:0.36712\n",
      "[222]\tvalidation_0-auc:0.65970\tvalidation_0-error:0.38453\tvalidation_1-auc:0.65567\tvalidation_1-error:0.36716\n",
      "[223]\tvalidation_0-auc:0.65973\tvalidation_0-error:0.38453\tvalidation_1-auc:0.65568\tvalidation_1-error:0.36713\n",
      "[224]\tvalidation_0-auc:0.65975\tvalidation_0-error:0.38449\tvalidation_1-auc:0.65569\tvalidation_1-error:0.36717\n",
      "[225]\tvalidation_0-auc:0.65976\tvalidation_0-error:0.38448\tvalidation_1-auc:0.65570\tvalidation_1-error:0.36715\n",
      "[226]\tvalidation_0-auc:0.65978\tvalidation_0-error:0.38448\tvalidation_1-auc:0.65571\tvalidation_1-error:0.36715\n",
      "[227]\tvalidation_0-auc:0.65980\tvalidation_0-error:0.38449\tvalidation_1-auc:0.65571\tvalidation_1-error:0.36719\n",
      "[228]\tvalidation_0-auc:0.65980\tvalidation_0-error:0.38449\tvalidation_1-auc:0.65572\tvalidation_1-error:0.36719\n",
      "[229]\tvalidation_0-auc:0.65981\tvalidation_0-error:0.38448\tvalidation_1-auc:0.65572\tvalidation_1-error:0.36718\n",
      "[230]\tvalidation_0-auc:0.65984\tvalidation_0-error:0.38444\tvalidation_1-auc:0.65572\tvalidation_1-error:0.36719\n",
      "[231]\tvalidation_0-auc:0.65985\tvalidation_0-error:0.38443\tvalidation_1-auc:0.65572\tvalidation_1-error:0.36714\n",
      "[232]\tvalidation_0-auc:0.65987\tvalidation_0-error:0.38444\tvalidation_1-auc:0.65573\tvalidation_1-error:0.36714\n",
      "[233]\tvalidation_0-auc:0.65988\tvalidation_0-error:0.38442\tvalidation_1-auc:0.65573\tvalidation_1-error:0.36718\n",
      "[234]\tvalidation_0-auc:0.65989\tvalidation_0-error:0.38441\tvalidation_1-auc:0.65574\tvalidation_1-error:0.36712\n",
      "[235]\tvalidation_0-auc:0.65991\tvalidation_0-error:0.38439\tvalidation_1-auc:0.65575\tvalidation_1-error:0.36714\n",
      "[236]\tvalidation_0-auc:0.65992\tvalidation_0-error:0.38438\tvalidation_1-auc:0.65575\tvalidation_1-error:0.36715\n",
      "[237]\tvalidation_0-auc:0.65993\tvalidation_0-error:0.38437\tvalidation_1-auc:0.65575\tvalidation_1-error:0.36716\n",
      "[238]\tvalidation_0-auc:0.65996\tvalidation_0-error:0.38434\tvalidation_1-auc:0.65575\tvalidation_1-error:0.36715\n",
      "[239]\tvalidation_0-auc:0.65997\tvalidation_0-error:0.38435\tvalidation_1-auc:0.65575\tvalidation_1-error:0.36714\n",
      "[240]\tvalidation_0-auc:0.65998\tvalidation_0-error:0.38435\tvalidation_1-auc:0.65575\tvalidation_1-error:0.36714\n",
      "[241]\tvalidation_0-auc:0.65999\tvalidation_0-error:0.38437\tvalidation_1-auc:0.65575\tvalidation_1-error:0.36718\n",
      "[242]\tvalidation_0-auc:0.66001\tvalidation_0-error:0.38435\tvalidation_1-auc:0.65577\tvalidation_1-error:0.36724\n",
      "[243]\tvalidation_0-auc:0.66002\tvalidation_0-error:0.38435\tvalidation_1-auc:0.65577\tvalidation_1-error:0.36724\n",
      "[244]\tvalidation_0-auc:0.66004\tvalidation_0-error:0.38435\tvalidation_1-auc:0.65579\tvalidation_1-error:0.36726\n",
      "[245]\tvalidation_0-auc:0.66006\tvalidation_0-error:0.38435\tvalidation_1-auc:0.65580\tvalidation_1-error:0.36724\n",
      "[246]\tvalidation_0-auc:0.66007\tvalidation_0-error:0.38429\tvalidation_1-auc:0.65580\tvalidation_1-error:0.36720\n",
      "[247]\tvalidation_0-auc:0.66008\tvalidation_0-error:0.38427\tvalidation_1-auc:0.65581\tvalidation_1-error:0.36721\n",
      "[248]\tvalidation_0-auc:0.66011\tvalidation_0-error:0.38426\tvalidation_1-auc:0.65582\tvalidation_1-error:0.36723\n",
      "[249]\tvalidation_0-auc:0.66012\tvalidation_0-error:0.38424\tvalidation_1-auc:0.65583\tvalidation_1-error:0.36724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_dec_tree.fit(X_res2, y_res2)\n",
    "\n",
    "eval_set = [(X_res2, y_res2), (X_test, y_test)]\n",
    "eval_metric = [\"auc\",\"error\"]\n",
    "clf_xgb2.fit(X_res2, y_res2, eval_metric=eval_metric, eval_set=eval_set, verbose=True)\n",
    "\n",
    "\n",
    "clf_rand_cl.fit(X_res2, y_res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.78      0.71     55376\n",
      "           1       0.62      0.46      0.53     43709\n",
      "\n",
      "    accuracy                           0.64     99085\n",
      "   macro avg       0.63      0.62      0.62     99085\n",
      "weighted avg       0.63      0.64      0.63     99085\n",
      "\n",
      "------------------------------------------------------------\n",
      "XG Boost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70     55376\n",
      "           1       0.61      0.45      0.52     43709\n",
      "\n",
      "    accuracy                           0.63     99085\n",
      "   macro avg       0.63      0.61      0.61     99085\n",
      "weighted avg       0.63      0.63      0.62     99085\n",
      "\n",
      "------------------------------------------------------------\n",
      "Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.77      0.70     55376\n",
      "           1       0.61      0.47      0.53     43709\n",
      "\n",
      "    accuracy                           0.64     99085\n",
      "   macro avg       0.63      0.62      0.62     99085\n",
      "weighted avg       0.63      0.64      0.63     99085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_dec_pred = clf_dec_tree.predict(X_test) #Verificação dos melhores desempenhos\n",
    "y_xgb_pred2 = clf_xgb2.predict(X_test)\n",
    "y_rand_cl = clf_rand_cl.predict(X_test)\n",
    "print(f'Decision Tree')\n",
    "print(classification_report(y_test, y_dec_pred))\n",
    "print('-'*60)\n",
    "print(f'XG Boost')\n",
    "print(classification_report(y_test, y_xgb_pred2))\n",
    "print('-'*60)\n",
    "print(f'Random Forest')\n",
    "print(classification_report(y_test, y_rand_cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [2, 11, 21, 30, 40, None],\n",
      " 'min_samples_leaf': [1, 2, 3, 4],\n",
      " 'min_samples_split': [2, 3, 4, 5, 10],\n",
      " 'n_estimators': [200, 466, 733, 1000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest \n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 4)] #Dados do RandomSearch\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 40, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 4, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2 ,3 ,4]\n",
    "\n",
    "# Create the random grid\n",
    "params_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "pprint(params_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator = clf_rand_cl, \n",
    "                                   param_distributions = params_grid, \n",
    "                                   n_iter = 10, \n",
    "                                   cv = 3, \n",
    "                                   verbose=2,\n",
    "                                   n_jobs = -1)\n",
    "\n",
    "#Chamada do RandomSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Wall time: 19min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [2, 11, 21, 30, 40, None],\n",
       "                                        'min_samples_leaf': [1, 2, 3, 4],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 10],\n",
       "                                        'n_estimators': [200, 466, 733, 1000]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "random_search.fit(X_res2, y_res2)\n",
    "#Teste com o Random Search ///// DEMORA MUITO TEMPO E NÃO TEM BONS RESULTADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603900183489597\n"
     ]
    }
   ],
   "source": [
    "print(random_search.cv_results_['mean_test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 733,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_depth': 11}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_deci = RandomForestClassifier(random_state = 42,  #Verificando os valores do RandomSearch\n",
    "                                     max_depth=11,\n",
    "                                     min_samples_split=5,\n",
    "                                     min_samples_leaf=2,\n",
    "                                     n_estimators =733\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=11, min_samples_leaf=2, min_samples_split=5,\n",
       "                       n_estimators=733, random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_deci.fit(X_res2, y_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_deci = clf_deci.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arvore de decisão\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70     55376\n",
      "           1       0.62      0.44      0.52     43709\n",
      "\n",
      "    accuracy                           0.63     99085\n",
      "   macro avg       0.63      0.61      0.61     99085\n",
      "weighted avg       0.63      0.63      0.62     99085\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Arvore de decisão')\n",
    "print(classification_report(y_test, y_pred_deci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovo = OneVsOneClassifier(clf_rand_cl) #Teste com OVO e OVR ////// Com apenas dois valores não faz diferença, depois de perceber, deixei pelo aprendizado\n",
    "ovr = OneVsRestClassifier(clf_rand_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(random_state=42))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovo.fit(X_res2, y_res2)\n",
    "ovr.fit(X_res2, y_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ovo = ovo.predict(X_test)\n",
    "y_ovr = ovr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'OvO Random Forest')\n",
    "print(classification_report(y_test, y_ovo))\n",
    "print('-'*60)\n",
    "print(f'OvR Random Forest')\n",
    "print(classification_report(y_test, y_ovr))\n",
    "print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Não ouve melhora na utilização do RandomSeach, e a base de dados grande torna o calculo muito demorado.\n",
    "#Melhor desempenho foi do clf_rand_cl onde o mesmo possui melhor valor para para classifcação de 1\n",
    "\n",
    "#Random Forest\n",
    "#              precision    recall  f1-score   support\n",
    "\n",
    "#           0       0.65      0.77      0.70     55376\n",
    "#           1       0.61      0.47      0.53     43709\n",
    "\n",
    "#    accuracy                           0.64     99085\n",
    "#   macro avg       0.63      0.62      0.62     99085\n",
    "#weighted avg       0.63      0.64      0.63     99085"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e26661ee5fdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_rand_cl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf_mat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_rand_cl)\n",
    "\n",
    "plot_confusion_matrix(conf_mat=cm)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
